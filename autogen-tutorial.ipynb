{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "[Tutorial](https://microsoft.github.io/autogen/0.2/docs/tutorial/introduction)\n",
    "\n",
    "Agent in autogen is an entity that can\n",
    "* send messages\n",
    "* receive message\n",
    "* generate a reply using models, tools etc.\n",
    "\n",
    "Agent can be extended to make it customizable and many agents can work together.\n",
    "\n",
    "Ex agent components:\n",
    "1. Human in the loop\n",
    "2. Ipython executor\n",
    "3. Tool executor (pdf creator)\n",
    "4. LLM\n",
    "5. Custom 1,2,3\n",
    "\n",
    "### Built-in : ConversableAgent\n",
    "\n",
    "1. A list of LLMs\n",
    "2. A code executor\n",
    "3. A function and tool executor\n",
    "4. A component for keeping human-in-the-loop\n",
    "\n",
    "Can switch each component on or off / customize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just generating a reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a collection of algorithms, but I'm ready and here to help you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"How are you doing today, ConversableAgent?\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles and conversations\n",
    "\n",
    "* Can assign 'roles' to agent ex: user, python coder etc.\n",
    "    - You can do this using **system_message** attribute of ConversableAgent\n",
    "* You can allow them to converse between each other.\n",
    "* Conversations can be used to make progress on a task (like we say in the image in the tutorial link)\n",
    "\n",
    "Below we create 2 comedian agents. We initiate a chat between them with 1 of them asking \"tell me a joke\" and they converse with each other. We give max_turns=2 i.e. each will speak twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a classic! Alright, here’s one for you: Why don’t scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Good one, Joe! I love that! Here’s a response for you: Why did the physicist break up with the biologist? \n",
      "\n",
      "There was no chemistry!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we configured their role as 'comedian', they returned appropriate reply (jokes)\n",
    "* The agent to the left of the **.initiate_chat** method speaks first.\n",
    "\n",
    "Let's try changing it to a conversation between a comedian and a data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mbiswa\u001b[0m (to sam):\n",
      "\n",
      "Hey nerd. How are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msam\u001b[0m (to biswa):\n",
      "\n",
      "Hey! I'm doing well, thanks for asking. How about you? What’s on your mind today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mbiswa\u001b[0m (to sam):\n",
      "\n",
      "I'm doing great, thanks! Just thinking about how weird it is that we have so many festivals in India. I mean, every month there's a new reason to celebrate, right? It’s like we’ve collectively decided that being serious is overrated. What about you? Any funny stories or thoughts you want to share?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msam\u001b[0m (to biswa):\n",
      "\n",
      "Absolutely, the variety of festivals in India is fascinating! It reflects the rich cultural diversity and the joy of coming together. It's like a never-ending cycle of celebrations!\n",
      "\n",
      "As for funny stories, I remember a time when I was in a data science meetup, and someone was trying to explain a complex algorithm using a cooking analogy. They compared machine learning models to baking a cake, where the data is the ingredients. It got a bit out of hand when they started talking about \"overfitting\" like it was a recipe gone wrong! It was hilarious and a bit chaotic but definitely made the concept stick! \n",
      "\n",
      "Do you have a favorite festival or celebration?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "biswa = ConversableAgent(\n",
    "    \"biswa\",\n",
    "    system_message=\"Your name is Biswa Kalyan Rath and you are a comedian from India.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "sam = ConversableAgent(\n",
    "    \"sam\",\n",
    "    system_message=\"Your name is Sam and you are a data scientist from silicon valley.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "result2 = biswa.initiate_chat(sam, message=\"Hey nerd. How are you?\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial => INTRODUCTION completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
