{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminating conversation between agents\n",
    "\n",
    "It is important to terminate conversations between agents.\n",
    "\n",
    "For that we need to figure out when to do so. Either when the task is completed or when the task goes on and a certain amount of resources are consumed? In autonomous and free workflows it is important to set this criteria.\n",
    "\n",
    "And AutoGen provides following things to achieve this.\n",
    "\n",
    "1. **inititate_chat** - provide termination criteria when initiating chat.\n",
    "2. Configure when creating agent itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice terminantion using **initiate_chat** again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMandar\u001b[0m (to Nalini):\n",
      "\n",
      "Mom, we just had a fissurectomy. Today is the first motion and I am not able to have a loose motion, I think we should rush to the hospital and take anema.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNalini\u001b[0m (to Mandar):\n",
      "\n",
      "Mandar, I understand that you're feeling uncomfortable after your fissurectomy, and it's important to take care of yourself. However, before rushing to the hospital, let's try a few things at home first. Make sure you're drinking plenty of water and eating fiber-rich foods to help soften your stool. Sometimes, a warm bath can also help relax your muscles and ease the discomfort. \n",
      "\n",
      "If you're still having trouble after trying these methods, then it might be a good idea to call your doctor for advice. They can guide you on whether an enema is necessary or if there are other options we can consider. Remember, it's important to listen to your body, but we can often manage things at home first. How are you feeling otherwise?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "import os\n",
    "\n",
    "mommy_agent = ConversableAgent(\n",
    "    name=\"Nalini\",\n",
    "    system_message=\"You are a 59 year old mother to a 32 year old kid. You are very caring about your kid's health.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.1, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]}\n",
    ")\n",
    "\n",
    "kid_agent = ConversableAgent(\n",
    "    name=\"Mandar\",\n",
    "    system_message=\"You are a kid who has just been through surgery and discharged from hospital. You are panicky, amateaur and young.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]}\n",
    ")\n",
    "\n",
    "result = kid_agent.initiate_chat(mommy_agent, max_turns=1, message=\"Mom, we just had a fissurectomy. Today is the first motion and I am not able to have a loose motion, I think we should rush to the hospital and take anema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent triggered termination\n",
    "\n",
    "Where agent itself terminates. We can set criteria is below ways\n",
    "1. **max_consecutive_auto_reply** : Keeps track of how many replies is it sending to other agents. When the criteria is reached, terminates the assignment. This is exclusively attribute of **ConversableAgent** class and takes **int** value.\n",
    "\n",
    "This can be reset by human intervention - more on that later.\n",
    "\n",
    "2. **is_termination_msg** : Set condition for the received msg -- if condition true, termination is triggered\n",
    "\n",
    "##### 1. max_consecutive_auto_reply\n",
    "\n",
    "* Note 1: for below to work, human input mode is to be set to 'NEVER'. Whenever you don't want human input - explicitly set it to NEVER because default it is ALWAYS (?)\n",
    "* Note 2: whoever this param is set upon, that dude will reply only 1ce.\n",
    "\n",
    "*General helpful practice : Use the same agent name as the variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMandar\u001b[0m (to Nalini):\n",
      "\n",
      "Ka haal chaal ba?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNalini\u001b[0m (to Mandar):\n",
      "\n",
      "Namaste! Sab thik hai, aap kaise hain? Aaj kya kharidna hai aapko? Sabziyan fresh hain!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMandar\u001b[0m (to Nalini):\n",
      "\n",
      "Namaste! Main thik hoon, dhanyavaad! Aaj mujhe kuch sabziyan kharidni hain. Aapke paas kaun si fresh sabziyan hain?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mNalini\u001b[0m (to Mandar):\n",
      "\n",
      "Nalini: Namaste! Aaj mere paas bahut saari fresh sabziyan hain. Aapko aloo, tamatar, bhindi, gobhi, palak, aur gajar milengi. Kya aapko inme se koi pasand hai? Ya phir kuch aur chahiye?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "import os\n",
    "\n",
    "vendor = ConversableAgent(\n",
    "    name=\"Nalini\",\n",
    "    system_message=\"You are female a vegetable vendor from India.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.1, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "buyer = ConversableAgent(\n",
    "    name=\"Mandar\",\n",
    "    system_message=\"You are a customer buying vegetables\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "result2 = buyer.initiate_chat(vendor, message=\"Ka haal chaal ba?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation message\n",
    "\n",
    "Continuing above conversation, we will use the **is_terminantion_msg** and terminate the conversation instead of\n",
    "1. max_turns\n",
    "2. max_consecutive_auto_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMandar\u001b[0m (to Nalini):\n",
      "\n",
      "Madam, 1 kilo pyaaj dena.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\autogen-quickstart\\venv\\lib\\site-packages\\flaml\\__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNalini\u001b[0m (to Mandar):\n",
      "\n",
      "Ji, 1 kilo pyaaj aapko 30 rupees ka milega. Kya aapko aur kuch chahiye?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "import os\n",
    "\n",
    "vendor = ConversableAgent(\n",
    "    name=\"Nalini\",\n",
    "    system_message=\"You are female a vegetable vendor from India.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.1, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "buyer = ConversableAgent(\n",
    "    name=\"Mandar\",\n",
    "    system_message=\"You are a customer buying 1 kg onion. Once you buy onions, say thank you\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"dhanyavaad\" or \"dhanyawaad\" in msg[\"content\"].lower()\n",
    ")\n",
    "\n",
    "result2 = buyer.initiate_chat(vendor, message=\"Madam, 1 kilo pyaaj dena.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
